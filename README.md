# PhysMamba-3DGS
PhysMamba-3DGS-Physics-Aware-Heterogeneous-Assisted-Gaussian-Splatting-for-Blur-Degraded-Image

3D Gaussian Splatting (3DGS) demonstrates exceptional rendering capabilities for novel view synthesis; however, its reconstruction quality degrades significantly under blur-related degradations such as motion blur and defocus artifacts. Existing approaches often rely on computationally intensive implicit neural representations or employ degradation models that fail to adequately capture the complex spatial characteristics of real-world blur. To address this, we propose Physics-Aware Heterogeneous Assisted Gaussian Splatting (PhysMamba-3DGS), a novel framework that integrates state space modeling with physical priors to achieve robust 3D reconstruction from blurry images. Our method introduces two key innovations: a depth-aware Mamba-Transformer hybrid architecture that models long-range dependencies with linear complexity, and a hybrid physical enhancement mechanism that jointly optimizes motion blur and defocus kernels within the 3DGS pipeline. Extensive experiments show that our approach achieves state-of-the-art performance on both synthetic and real-world blurry datasets, delivering an average PSNR improvement of 15.6\% while maintaining real-time rendering efficiency.

## üîç Overview

<img width="1493" height="521" alt="main" src="https://github.com/user-attachments/assets/7a3d556d-b317-4dfd-8174-03010fda9707" />

*Figure 1: The overall architecture of our proposed PhysMamba-3DGS framework.*

## üìπ More Samples


https://github.com/user-attachments/assets/d6a767c8-836e-4420-8dac-54964ebfa89a


https://github.com/user-attachments/assets/b96ff6c7-185f-4780-8299-f5a3bfecf3dd

*Video 1: Comparative results showcasing our method's performance on synthetic and real-world blurry datasets.*


## Installation

Coming soon.
